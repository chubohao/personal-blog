<!doctype html>
<html lang="en">

    <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="Bohao Chu, and Bootstrap contributors">
    <title>Smart Wardrobe | Bohao Chu</title>
    <link href="assets/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom style sheet -->
    <link type="text/css" rel="stylesheet" href="assets/css/style.css"/>

    <!-- Google font -->
    <link href="https://fonts.googleapis.com/css?family=Nunito+Sans:700%7CNunito:300,600" rel="stylesheet">

    <!--Title Icon-->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.9.1/font/bootstrap-icons.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
    </head>


    <body>

        <header class="fixed-top header"></header>

		<main>
			<div class="section px-0">
				<div id="post-header" class="page-header pt-5" style="background-image: url('assets/img/wardrobe/bg.png'); background-color: #F5F5F5; background-position-y: 75%; background-position-x: 90%; background-size: auto 80%">
					<div class="container">
						<div class="row">
							<div class="col-md-10 col-sm-11 post-meta">
								<a class="post-category cat-2" href="#">Machine Learning</a>
								<span class="post-date text-dark">Oct 3, 2022 </span>
								<br><br>
								<h1 class="text-dark">Voice Controlled Smart Wardrobe</h1>
								<h3 class="text-dark pt-3">
									Automatic Clothes Pickup and Storage Wardrobe Based on Speech Recognition Control
								</h3>
								<p>
									<span class="text-dark">
										Bohao Chu, Faquan Wang, Shuaikang Liu, and Yangjie Cao
									</span>
								</p>
								<button type="button" class="btn btn-dark btn-lg btn-circle me-3">
                                    <span class="fa fa-file-pdf-o"></span>
                                </button>
								<button type="button" class="btn btn-dark btn-lg btn-circle">
                                    <span class="fa fa-graduation-cap"></span>
                                </button>
							</div>
						</div>
					</div>
				</div>
			</div>

			<div class="section px-0">
				<!-- container -->
				<div class="container">
					<!-- row -->
					<div class="row">
						<!-- POST MAIN -->
						<div class="col-md-8 pe-md-5">

							<h3>INTRODUCTION</h3>

							<div class="section-row">
								<figure class="figure-img text-center">
									<img class="img-responsive" src="assets/img/wardrobe/2.png" alt="" width="100%">
									<p class="px-3 pt-3 text-center">
										<small><strong>Figure 1.</strong> The relationship between the complexity of <br> networking and deployment and the number of sensors or sensing purposes.</small>
									</p>
								</figure>
							</div>

							<div class="row">
								<h4>
									BACKGROUND
								</h4>
								<p>
									In traditional IoT scenarios, Specific-Purpose Sensor (SPS) or Distributed Multi-Sensor (DMS) are usually deployed directly on different locations or objects to sense diverse purposes, However, the number of sensing purposes always conflict with the complexity of networking and deployment. Integrated Multi-Sensor Tag (IMST) alleviates this problem, such as Texas Instruments <i>SimpleLink SensorTag</i>, and Laput's <i>Synthetic Sensors</i>, with multiple sensors integrated on a small board to indirectly monitor a large context,  without direct instrumentation of objects. But due to the limited computing power of IMST, a large amount of raw data still needs to be sent to the remote server for processing through wireless technologies such as <i>Bluetooth</i> or <i>WiFi</i>, which may lead to processing delays, data leakage or intrusion.
								</p>

								<h4>
									MOTIVATION
								</h4>
								<p>
									With the rapid increase in computing power of end devices, many machine learning models are popular for inference on end devices. With the help of real-time data from sensors, the activities that are happening in the environment can be analyzed and recognized in real-time, which has a lot of demand and promise in the field of autonomous driving, sports, healthcare, etc.
								</p>

								<h3 class="mt-4">METHOD</h3>

								<p>
									In this work, we explore the concept of <strong>Edge Computing Sensor Kit (ECSK)</strong> based on the former work. We designed a new type of hardware that integrates several different types of sensors, including a camera and a microphone, on a small board, while adding a powerful processor and Tensor Processing Unit, which allows algorithmic models and applications to run directly on it instead of on a remote server. Each sensor has a task channel, and multiple sensors can independently perform data sampling and feature extraction with concurrency. Feature data from different sensor channels are used to achieve real-time recognition of general activities in the environment (e.g., robotic arm movement) by a machine learning based multi-sensor information fusion algorithm.
								</p>



								<h3 class="mt-4">
									RESULT
								</h3>
								<p>
									After completing the model training, we deployed our system in six real scenarios, and the deployment location of ECSK. In each scenario, ECSK continued the identification for each real-time activity, and we kept 50 positive and negative examples for each activity to ensure a balanced sample. We counted the confusion matrix, accuracy, precision, recall and F1 score for the 27 activities in scenarios, and finally the F1 score was used as the reference metric. We rounded all the values.
								</p>


								


								<h3 class="mt-4">
									KEYWORDS
								</h3>
								<p class="text-dark">
									<strong>
										Edge Computing Sensor Kit, Information Fusion, Machine Learning, Real-time Activity Recognition, Digital Twin, Data Visualization.
									</strong>
								</p>

							</div>

						</div>

						<!-- POST ASIDE -->
						<div class="col-md-4">
							<div class="row mb-3">
								<h3>MATERIAL</h3>

								<h4>EXPERIMENT</h4>
								<figure class="figure-img text-center">
									<img class="img-responsive" src="assets/img/wardrobe/1.jpg" alt="" width="100%">
									<p class="px-3 pt-3 text-center">
										<small ><strong>Figure 6.</strong> Schematic of our sensor board and the layout of the sensors and other modules.</small>
									</p>
								</figure>

								<iframe width="100%" height="250px" src="https://www.youtube.com/embed/pEYddBrC43A" style="border:none" allowfullscreen></iframe>
								<p class="px-3  pt-3 text-center">
									<small><strong>Video 1.</strong> Someone famous in Source Title.</small>
								</p>

								<iframe width="100%" height="250px" src="https://www.youtube.com/embed/427Y80wttsU" style="border:none" allowfullscreen></iframe>
								<p class="px-3  pt-3 text-center">
									<small><strong>Video 1.</strong> Someone famous in Source Title.</small>
								</p>
								
							</div>


							<div class="row mb-3">
								<h4>ARCHIVE</h4>
								<ul>
									<li><a href="#">Wei, Fuyin, Fei Xiang, Bohao Chu, and Bernd Noche. "Feature fusion algorithm based on modular scalable integrated sensor behavior recognition." Logistics Journal: Proceedings 2021, no. 17 (2021).</a></li>
								</ul>
							</div>




						</div>
						<!-- /aside -->
					</div>
					<!-- /row -->
				</div>
				<!-- /container -->
			</div>
			<!-- /section -->
		</main>


        <footer class="section bg-secondary mt-5 footer"></footer>
        <script src="assets/js/bootstrap.bundle.min.js"></script>
        <script>
            addEventListener("DOMContentLoaded", function() {
                $(".header").load("components/header.html",function(){});
                $(".footer").load("components/footer.html",function(){});
            });
        </script>

    </body>
</html>
