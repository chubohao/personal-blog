<!doctype html>
<html lang="en">

    <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="Bohao Chu, and Bootstrap contributors">
    <title>ECG | Bohao Chu</title>
    <link href="assets/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom style sheet -->
    <link type="text/css" rel="stylesheet" href="assets/css/style.css"/>

    <!-- Google font -->
    <link href="https://fonts.googleapis.com/css?family=Nunito+Sans:700%7CNunito:300,600" rel="stylesheet">

    <!--Title Icon-->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.9.1/font/bootstrap-icons.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
	<script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/styles/atom-one-dark.min.css">
	<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/highlight.min.js"></script>

    <body>

        <header class="fixed-top header"></header>

		<main>
			<div class="section px-0">
				<div id="post-header" class="page-header pt-5" style="background-image: url('assets/img/ecg/bg.png'); background-position-y: 90%; background-position-x: 90%; background-size: auto 80%">
					<div class="container">
						<div class="row">
							<div class="col-md-10 col-sm-11 post-meta">
								<a class="post-category cat-1" href="#">Machine Learning</a>
								<a class="post-category cat-2" href="#">Embedded System</a>
								<span class="post-date">Oct 3, 2022 </span>
								<br><br>
								<h1>Edge Computing Vision Gateway</h1>
								<h3 class="text-light pt-3">
								TPU Accelerated Video Gateway for Visual Computing.
								</h3>
								<p>
									<span class="text-light pt-2">
										Bohao Chu, Chao Wang, and Yangjie Cao
									</span>
								</p>
							</div>
						</div>
					</div>
				</div>
			</div>

			<div class="section">
				<!-- container -->
				<div class="container">
					<!-- row -->
					<div class="row">
						<!-- POST MAIN -->
						<div class="col-md-8 pe-md-5">
							<h3>INTRODUCTION</h3>
							<div class="section-row">
								<figure class="figure-img text-center">
									<img class="img-responsive" src="assets/img/ecg/arch.png" alt="" width="100%">
									<figcaption class="my-3">
										<strong>Figure 1.</strong> Archtecture of Edge Computing Vision Gateway.
									</figcaption>
								</figure>
							</div>
							<h4>
								BACKGROUND
							</h4>
							<p>
								We know that in the construction site area, construction workers must wear helmets to guard against falling objects. But even though supervisors give this requirement to construction workers, someone always forgets or chooses not to wear a helmet for various reasons, which brings great safety risks to his life. Previously, supervisors often patrolled regularly to detect whether each person was wearing a helmet correctly, but this was time-consuming and labor-intensive, and the supervisors were unable to monitor in real time. Therefore, they want to be able to use visual computing to determine whether construction workers are wearing helmets, and if someone is found not wearing a helmet, a warning will be issued.
							</p>

							<h4>
								MOTIVATION
							</h4>
							<p>
								Object recognition or action recognition based on visual computing has received a lot of attention and made great progress, such as ImageNet, YOLO, and so on. However, this area is still full of many challenges, such as how to improve the speed of video transmission, the speed of model recognition, and the generalization ability of models. This work will focus on these problems and implement a vision gateway based on image recognition.
							</p>

							<div class="row">
								

<h3 class="mt-4">METHOD</h3>

<h4>
1. mlti-camera video concurrent pull stream
</h4>
<p>
This work uses the Hikvision camera that supports RTSP protocol, according to the product manual can be known to pull the video stream as shown in the base code 1. To realize multiple pulling cameras, we use a multi-threaded approach.
</p>

<pre class="hljs card m-2">
<code>
import cv2
# Camera Login Information
ip='192.168.2.111'
user='admin'
password='123456'
# rtsp://[username]:[passwd]@[ip]:[port]/[codec]/[channel]/[subtype]/av_stream
capture = cv2.VideoCapture("rtsp://"+ user +":"+ password +"@" + ip + ":554/h264/ch1/main/av_stream")
ret, frame = capture.read()
cv2.namedWindow(ip, 0)
cv2.resizeWindow(ip, 500, 300)
while ret:
	ret, frame = capture.read()
	cv2.imshow(ip,frame)
	if cv2.waitKey(1) & 0xFF == ord('q'):
		break
cv2.destroyAllWindows()
capture.release()
</code>
</pre>



<h4 class="mt-4">
2. tagging of people's avatars in video streams
</h4>
<p>
In this work, we explore the concept of <strong>Edge Computing Sensor Kit (ECSK)</strong> based on the former work. We designed a new type of hardware that integrates several different types of sensors, including a camera and a microphone, on a small board, while adding a powerful processor and Tensor Processing Unit, which allows algorithmic models and applications to run directly on it instead of on a remote server. Each sensor has a task channel, and multiple sensors can independently perform data sampling and feature extraction with concurrency. Feature data from different sensor channels are used to achieve real-time recognition of general activities in the environment (e.g., robotic arm movement) by a machine learning based multi-sensor information fusion algorithm.
</p>

<pre class="hljs card m-2">
<code>
import cv2
cv2.namedWindow("she xiang tou buzhu")
# download from opencv
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
while True:
	ret, frame = capture.read()
	gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)
	# detect avatar
	faces = face_cascadedetectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(20, 20), flags=cv2.CASCADE_SCALE_IMAGE)
	# lable avatar
	for (x, y, w, h) in faces:
		cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
		cv2.imshow('she xiang tou', frame)
		if cv2.waitKey(5) & 0xFF == ord('q'):
			break
</code>
</pre>

<h4 class="mt-4">
3. Helmet Recognition based on YOLOv5
</h4>
<p>
	我们基于YOLOv5训练了一个安全帽识别的模型
</p>
<pre class="hljs card m-2">
<code>
import cv2
cv2.namedWindow("she xiang tou buzhu")
# download from opencv
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
while True:
	ret, frame = capture.read()
	gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)
	# detect avatar
	faces = face_cascadedetectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(20, 20), flags=cv2.CASCADE_SCALE_IMAGE)
	# lable avatar
	for (x, y, w, h) in faces:
		cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
		cv2.imshow('she xiang tou', frame)
		if cv2.waitKey(5) & 0xFF == ord('q'):
			break
</code>
</pre>


								


								<h3 class="mt-4">
									RESULT
								</h3>

								<figure class="figure-img text-center row">
									<img class="img-responsive col-6" src="assets/img/ecg/5.jpg" alt="" width="100%">
									<img class="img-responsive col-6" src="assets/img/ecg/5r.jpg" alt="" width="100%">
								</figure>
								<figure class="figure-img text-center row">
									<img class="img-responsive col-6" src="assets/img/ecg/4.jpg" alt="" width="100%">
									<img class="img-responsive col-6" src="assets/img/ecg/4r.jpg" alt="" width="100%">
								</figure>
								<figure class="figure-img text-center row">
									<img class="img-responsive col-6" src="assets/img/ecg/1.jpg" alt="" width="100%">
									<img class="img-responsive col-6" src="assets/img/ecg/1r.jpg" alt="" width="100%">
								</figure>
								<figure class="figure-img text-center row">
									<img class="img-responsive col-6" src="assets/img/ecg/2.jpg" alt="" width="100%">
									<img class="img-responsive col-6" src="assets/img/ecg/2r.jpg" alt="" width="100%">
								</figure>

								<figure class="figure-img text-center row">
									<img class="img-responsive col-6" src="assets/img/ecg/3.jpg" alt="" width="100%">
									<img class="img-responsive col-6" src="assets/img/ecg/3r.jpg" alt="" width="100%">
								</figure>
								

								<h3 class="mt-4">
									KEYWORDS
								</h3>
								<p class="text-dark">
									<strong>
										Edge Computing Sensor Kit, Information Fusion, Machine Learning, Real-time Activity Recognition, Digital Twin, Data Visualization.
									</strong>
								</p>

							</div>

						</div>

						<!-- POST ASIDE -->
						<div class="col-md-4">
							<div class="row mb-5">
								<h3>MATERIALS</h3>

								<h4>HARDWARE</h4>
								<p>
									ECSK can sense, process, and recognize the general activities happening in the environment in real-time like a human, which wi,ECSK can sense, process, and recognize the general activities happening in the environment in real-time like a
								</p>
								<figure class="figure-img text-center">
									<img class="img-responsive" src="assets/img/ecg/hardware.png" alt="" width="100%">
								</figure>

								<figure class="figure-img text-center">
									<img class="img-responsive" src="assets/img/ecg/title.png" alt="" width="100%">
								</figure>
								
								<p>
									ECSK can sense, process, and recognize the general activities happening in the environment in real-time like a ECSK can sense, process, and recognize the general activities happening in the environment in real-time like a
								</p>
								<figure class="figure-img text-center">
									<img class="img-responsive" src="assets/img/ecg/gateway-3.png" alt="" width="100%">
								</figure>

								<h4>EXPERIMENT</h4>
								<p>
									TO DO ...
								</p>
								
							</div>
						</div>
						<!-- /aside -->
					</div>
					<!-- /row -->
				</div>
				<!-- /container -->
			</div>
			<!-- /section -->
		</main>


        <footer class="section bg-secondary mt-5 footer"></footer>
        <script src="assets/js/bootstrap.bundle.min.js"></script>
        <script>
			hljs.initHighlightingOnLoad();
            addEventListener("DOMContentLoaded", function() {
                $(".header").load("components/header.html",function(){});
                $(".footer").load("components/footer.html",function(){});
            });
        </script>

    </body>
</html>
